{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split,KFold,GridSearchCV,cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix,r2_score,mean_squared_error,precision_recall_curve,f1_score,auc,roc_auc_score,roc_curve,make_scorer\nfrom sklearn.externals import joblib",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "np.random.seed(9)   \n\ntrain_data=pd.read_csv('Data/AdvWorksCusts.csv')\nprint('\\t\\t\\tCustomer Spending Beheviour Prediction\\n\\n\\t\\tTraining Data\\n',train_data.head(),'\\n\\n\\t\\tData Information\\n')\ntrain_data.info()\n\nlabel_data1=pd.read_csv('Data/AW_AveMonthSpend.csv')\nlabel_data2=pd.read_csv('Data/AW_BikeBuyer.csv')\n\ntrain_data.drop_duplicates(subset='CustomerID',keep='last',inplace=True)\nlabel_data1.drop_duplicates(subset='CustomerID',keep='last',inplace=True)\nlabel_data2.drop_duplicates(subset='CustomerID',keep='last',inplace=True)\n\nlabel1=label_data1['AveMonthSpend']\nlabel2=label_data2['BikeBuyer']\n\ntrain_data['age']=(train_data['BirthDate'].apply(lambda x:x[:4])).apply(lambda x:2019-np.int64(x))\n\ntrain_data.drop(columns=['CustomerID','Title','FirstName','MiddleName','LastName','City','StateProvinceName','Suffix','AddressLine2','AddressLine1','PostalCode','PhoneNumber','BirthDate'],inplace=True)\n\nnum_col=['YearlyIncome','age']                     \ncat_col=['CountryRegionName','Education','Occupation','Gender','MaritalStatus','HomeOwnerFlag','NumberCarsOwned','NumberChildrenAtHome','TotalChildren']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def vizual(data,columns,label=label2,type='bar'):\n    if type=='bar':\n        for col in columns:\n            sns.countplot(y=data[col])\n            plt.show()\n    if type=='hist':\n        for col in columns:\n            sns.distplot(data[col],bins=30)\n            plt.show()\n    if type=='scatter':\n        for col in columns:\n            sns.scatterplot(col,label,data=data,s=10)\n            plt.show()\n    if type=='violin':\n        for col in columns:\n            if(data[col].dtype=='object'):\n                sns.violinplot(col,label,data=data)\n                plt.show()\n            else:\n                sns.violinplot(label,col,data=data)\n                plt.show()  \n\nprint('\\n\\t\\tData Vizualization\\n\\n\\tBar Plot')     \nvizual(train_data,cat_col,type='bar',label=label2[label2==1])\nprint('\\tHistogram Plot')\nvizual(train_data,num_col,type='hist',label=label2[label2==1])\nprint('\\tScatter Plot')\nvizual(train_data,num_col,type='scatter',label=label1)\nprint('\\tViolin Plot')\nvizual(train_data,train_data.columns,type='violin')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def scale(data,columns,type='min_max'):\n    for col in columns:\n        if(type=='z score'):\n            data[col]=(data[col]-np.mean(data[col]))/(np.std(data[col]))\n        if(type=='min_max'):\n            data[col]=(data[col]-np.min(data[col]))/(np.max(data[col])-np.min(data[col]))\n        if(type=='log'):\n            data[col]=np.log(data[col])\n        if(type=='inverse'):\n            data[col]=(1/data[col])\n    return data       ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def preperation(data):\n    data['Gender'].replace({'M':0.9,'F':0.1},inplace=True)\n    data['NumberChildrenAtHome'].replace({0:0.1,1:0.3,2:0.5,3:0.7,4:0.9,5:1.1},inplace=True)\n\n    data['s_age']=data['Gender']*data['YearlyIncome']/data['age']*data['NumberChildrenAtHome']\n    data['old']=data['age'].apply(lambda x:0 if x<=60 else 1)\n    data['gnch']=data['Gender']*data['NumberChildrenAtHome']\n    \n    data['NumberChildrenAtHome'].replace({1:0,2:1,3:1,4:1,5:1},inplace=True)\n    data['NumberCarsOwned'].replace({1:0,2:0,3:1,4:1},inplace=True)\n    data['TotalChildren'].replace({1:0,2:0,3:1,4:1,5:1},inplace=True)\n    \n    data=pd.get_dummies(data)\n    data=scale(data,columns=['s_age'],type='log')\n    data=scale(data,data.select_dtypes('int64','float64'))\n    \n    return data\n\ntrain_data=preperation(train_data)\n\nprint('\\n\\t\\tData Vizualization After Data Modification\\n\\n\\tHistogram Plot')     \nvizual(train_data,['s_age'],type='hist')\nprint('\\tScatter Plot')\nvizual(train_data,['s_age'],type='scatter',label=label1)\nprint('\\tBar Plot')     \nvizual(train_data,['gnch','old'],type='bar')\nprint('\\tViolin Plot')\nvizual(train_data,['gnch','old'],type='violin')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def regression(x,y=label1,test_size=0.2):    \n    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n    model=make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\n    model.fit(x_train,y_train)\n    return model,x_test,y_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def classify(x,y=label2,test_size=0.2):\n    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n    model=make_pipeline(PolynomialFeatures(degree=2),LogisticRegression(C=0.7,penalty='l1',class_weight='balanced',solver='liblinear'))\n    model.fit(x_train,y_train)\n    return model,x_test,y_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def roc_pr_f1(model,x,y,show=False,plot=False,show_all=False):\n    no_skill_probs=[0 for i in range(len(y))]\n    lr_probs=model.predict_proba(x)[:,1]\n    pred=model.predict(x)\n        \n    ns_fpr,ns_tpr,_=roc_curve(y,no_skill_probs)\n    lr_fpr,lr_tpr,_=roc_curve(y,lr_probs)\n    \n    ns_precision,ns_recall,_=precision_recall_curve(y,no_skill_probs)\n    lr_precision,lr_recall,_=precision_recall_curve(y,lr_probs)\n    ns_f1,ns_pr_auc,ns_roc_auc=0.0,auc(ns_recall,ns_precision),roc_auc_score(y,no_skill_probs)\n    lr_f1,lr_pr_auc,lr_roc_auc=f1_score(y,pred),auc(lr_recall,lr_precision),roc_auc_score(y,lr_probs)\n    \n    if show or show_all:\n        print('Accuracy score=',accuracy_score(y,pred))\n        print('No Skill: F1 Score=',ns_f1,'\\t\\tPR AUC=',ns_pr_auc,' ROC AUC=',ns_roc_auc)\n        print('Logistic: F1 Score=',lr_f1,' PR AUC=',lr_pr_auc,' ROC AUC=',lr_roc_auc)\n        \n    if plot or show_all:\n        print('\\n\\tPrecision VS Recall')\n        plt.plot(ns_recall,ns_precision,marker='.',label='No_Skill')\n        plt.plot(lr_recall,lr_precision,marker='.',label='Logistics')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.legend()\n        plt.show()\n        \n        print('\\n\\tROC Curve')\n        plt.plot(ns_fpr,ns_tpr,marker='.',label='No_Skill')\n        plt.plot(lr_fpr,lr_tpr,marker='.',label='Logistics')\n        plt.xlabel('False positive rate')\n        plt.ylabel('True positive rate')\n        plt.legend()\n        plt.show()\n    \n    return lr_roc_auc,lr_pr_auc,lr_f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def conf_mat(y_true,y_pred):\n    cfm = confusion_matrix(y_true,y_pred)\n    sns.heatmap(cfm, annot=True)\n    print('\\n\\tConfusion Matrix')\n    plt.xlabel('Predicted classes')\n    plt.ylabel('Actual classes')  \n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def evaluate(model,x_test,y_test,type='class',conf=True,show=False,plot=False,show_all=False):\n    if type=='class':\n        pred=model.predict(x_test)\n        roc_auc,pr_auc,f1=roc_pr_f1(model,x_test,y_test,show,plot,show_all)\n        if conf or show_all:\n            conf_mat(y_test.values,pred)\n    \n        return (1-roc_auc)    \n    \n    if type=='reg':\n        pred=model.predict(x_test)\n        rmse=np.sqrt(mean_squared_error(y_test,pred))\n        \n        if show or show_all:\n            print('R2 score = ',r2_score(y_test,pred),'\\nRoot Mean Squared Error=',rmse) \n            \n        if plot or show_all:\n            error=pred-y_test\n            plt.scatter(y_test,error,s=1)\n            plt.xlabel('Actual value')\n            plt.ylabel('Error')\n            plt.show()\n            \n            error.hist(figsize=(5,5),bins=30)\n            plt.xlabel('Error')\n            plt.ylabel('Count')\n            plt.show()\n            \n            plt.scatter(y_test,pred,s=1)\n            plt.xlabel('Actual value')\n            plt.ylabel('Predicted Value')\n            plt.show()\n            \n        return rmse ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cv(model,data,label,scoring='roc_auc',fold=5):\n    kfold=KFold(n_splits=fold,shuffle=True,random_state=6)\n    score=cross_val_score(model,data,label,scoring=scoring,cv=kfold)\n    return (score.mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def nested_cv(model,data,label,scoring='roc_auc',fold=10):\n    inside=KFold(n_splits=fold,shuffle=True,random_state=2)\n    outside=KFold(n_splits=fold,shuffle=True,random_state=7)\n    clf=GridSearchCV(model,param_grid={\"C\":[0.1,0.7,1,10]},cv=inside,scoring=make_scorer(roc_auc_score),return_train_score=False)\n    clf.fit(data,label)\n    score=cross_val_score(clf,data,label,scoring=scoring,cv=outside)\n    return clf.best_estimator_.C,(score.mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def predict(model,x_test,y_test):    \n    predicted=pd.DataFrame()\n    predicted['Actua Value']=y_test\n    predicted['Predicted Value']=model.predict(x_test)\n    return predicted",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "reg_model,x_test,y_test=regression(train_data)\nprint('\\n\\t\\tPrediction on Validation set\\n\\tAvarage Monthly Speding of Customers\\n',predict(reg_model,x_test,y_test),'\\n\\n\\tEvaluation\\n')\nevaluate(reg_model,x_test,y_test,type='reg',show_all=True)\njoblib.dump(reg_model,'Models/reg_model.sav')\ncv_score=cv(reg_model,train_data,label=label1,scoring='r2')\nprint('\\nMean R2 score after cross validation = ',cv_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "evaluate(class_model,x_test,y_test,type='class',show_all=True)\ncv_score=cv(class_model,train_data,label=label2,scoring='roc_auc')\nprint('\\nMean ROC AUC after cross validation = ',cv_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
      "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
